---
title: "xxIRT: Practical Item Response Theory and Computer-Based Testing in R"
author: Xiao Luo
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  github_document:
    fig_width: 6
    fig_heigh: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval=FALSE)
library(xxIRT)
library(reshape2)
library(dplyr)
library(ggplot2)
set.seed(38624)
```


### Table of Contents
* [Installation](#installation)
* [Introduction](#introduction)
* [Package Modules](#package-modules)
    + [IRT Models](#irt-models)
    + [IRT Utils](#irt-utils)
    + [Parameter Estimation](#parameter-estimation)
    + [Automated Test Assembly](#automated-test-assembly)
    + [Computerized Adaptive Testing](#computerized-adaptive-testing)
    + [Multistage Testing](#multistage-testing)
* [Graphical User Interfaces](#graphical-user-interfaces)
* [Ending](#ending)


### Installation
To install a stable version from [CRAN](https://cran.r-project.org/package=xxIRT), call `install.packages("xxIRT")` in R console. To install the most recent version from [GitHub](https://github.com/xluo11/xxIRT), call `devtools::install_github("xluo11/xxIRT")` in R console (if *devtools* package has not been installed yet, install it first). To remove the installed package, call `remove.packages("xxIRT")` in R console. 


### Introduction

*xxIRT* is a R package designed to implement latest advancements in psychometric research, especially pertaining to computer-based testing, in hopes of facilitating the psychometric research and operations in practice. The package is organized into six modules:

0. IRT models
1. IRT Utils
2. Parameter Estimation
3. Automated Test Assembly
4. Computerized Adaptive Testing
5. Multistage Testing

The application programming interface (API) is for the intermediate R users who are familiar with R, whereas the graphic user interface (GUI) is for novice users who don't feel like writing code in R. 


#### Package Modules

##### IRT Models
The 3-parameter-logistic (3PL) model was introduced by Birnbaum[^1], which uses three item parameter (a, b, and c) and one people parameter ( *$\theta$*) to describe the probabilistic relationship of the item-people interaction. When fixing the *a*-parameter to 0.58 (since D=1.7) and *c*-parameters to 0, this model becomes **mathematically** equivalent to the Rasch model[^2].

This module creates a S3 R object representing the 3PL model. It contains parameter and response data, as well as functions to compute the probability, information and likelihood. Use `model_3pl(people, items, responses)` or `model_3pl(theta, a, b, c, responses)` to create a *3PL* object. The *people* argument needs to be a data frame with a column named *theta*, the *items* argument a data frame with columns named *a*, *b*, and *c*, and the *responses* argument a matrix or data frame with dimensionality equal to the numbers of people and items. Alternatively, use *theta*, *a*, *b*, and *c* arguments to pass in numeric vectors of parameters directly. Upon its creation, the object comes with functions to compute the probability (`P(x)`), information (`I(x)`), and likelihood (`L(x, log)`) using the 3PL model. It also provides a helper function for generating data (`gendata(n.people, n.items, people, items, ...)`). Pass in the number of people (`n.people`) and items (`n.items`) to generate parameters, or pass in the people (`people`) or item (`items`) parameters to fix parameters in data generation. By default, the *$\theta$* parameter are drawn from a normal distribution (`theta.mean=0`, `theta.sd=1`), *a*-parameter from a lognormal distribution (`a.mean=0`, `a.sd=0.2`), *b*-parameters from a normal distribution (`b.mean=0`, `b.sd=1`), and *c*-parameters from a beta distribution (`c.alpha=5`, `c.beta=46`).

[^1]: Birnbaum, A. (1968). Some latent trait models. In F.M. Lord & M.R. Novick, (Eds.), Statistical theories of mental test scores. Reading, MA: Addison-Wesley.
[^2]: Rasch, G. (1966). An item analysis which takes individual differences into account. British journal of mathematical and statistical psychology, 19(1), 49-57.

###### Examples
```{r, results='hide'}
### create a 3pl model using given parameters
theta <- c(-1, 0, 1)
a <- c(.588, 1)
b <- c(-1, 1)
c <- c(0, .2)
u <- matrix(c(1, 0, 1, 0, 1, 0), nrow=3)
people <- data.frame(theta=theta)
items <- data.frame(a=a, b=b, c=c)

# create 3pl model using different arguments
model_3pl(people=people, items=items, responses=u) 
model_3pl(people=people, items=items) 
model_3pl(theta=theta, a=a, b=b, c=c) 
model_3pl(people=people, a=a, b=b, c=c) 
model_3pl(theta=theta, items=items) 

# compute Probability, Information, Likelihood by calling itself
x <- model_3pl(people=people, items=items, responses=u)
x$P(x)
x$I(x)
x$L(x)

# compute Probability, Information, Likelihood by calling the class object
model_3pl()$P(x)
model_3pl()$I(x)
model_3pl()$L(x)

### create a 3PL model using generated data
x <- model_3pl()$gendata(5, 3)
x$P(x)
x$I(x)
x$L(x)
```


##### IRT Utils
Item response theory (IRT) is a family of measurement models describing the relationship between observed responses and unobserved item/people parameters. It has been widely used to design and analyze large-scale high-stakes psychological and educational assessments. It is the foundation of some advanced applications such as computerized adaptive testing and multistage testing. See Hambleton and Swaminathan's [^3] and Lord's [^4] books for more details pertaining to IRT.

This module provides a collection of functions for commonly-used computations and graphing in IRT. For example,

* `irt_stats(obj, stats, summary, fun)`: compute probability, information, or likelihood, and summarize it over *people* or *item* using customized functions optionally.
* `irt_select(obj, people_index, items_index)`: subset data
* `irt_sample(obj, n.people, n.items)`: sample data
* `irt_rescale_3pl(obj, parameter, mean, sd)`: rescale parameters to the new scale of the *$\theta$* or *b* parameters. 
* `plot(obj, stats, total)`: visualize the specified statistics

[^3]: Hambleton, R. K., & Swaminathan, H. (1985). Item response theory: Principles and applications. New York, NY: Springer.
[^4]: Lord, F. M. (1980). Applications of item response theory to practical testing problems. New York NY: Routledge.

###### Examples
```{r}
# create a 3pl model using generated data
x <- model_3pl()$gendata(3, 5)

# compute probability, summed over items
irt_stats(x, "prob", summary="people", fun=sum)
# compute information, people(rows) by items (columns)
irt_stats(x, "info")
# compute likelihood, multiplied over items
irt_stats(x, "lik", summary="people", fun=prod)

# retain items [1, 3, 5] and people [2, 4]
irt_select(x, c(1, 3), c(2, 4))
# sample 5 people and 3 items
irt_sample(x, 5, 3)

# rescale parameters
x <- irt_rescale_3pl(x, "theta", 0, 1)
c(mean=mean(x$people$theta), sd=sd(x$people$theta))
x <- irt_rescale_3pl(x, "b", 0, 1)
c(mean=mean(x$items$b), sd=sd(x$items$b))

# draw item characteristic curves
plot(x, stats='prob', total=FALSE)
# draw test information functions
plot(x, stats='info', total=TRUE)
# draw response log-likelihood
plot(x, stats='loglik', total=TRUE)
```


##### Parameter Estimation
This module provides an interface for estimating people and item parameters in the 3PL model with dichotomous responses. Two estimators are available: the maximum likelihood estimator `estimate_mle(u, ...)` and the Bayesian estimator `estimate_bayesian(u, ...)`. To fix values, put the values at the corresponding positions in the `a` (discrimination), `b` (difficulty), `c` (pseudo-guessing), and `t` (ability) arguments, and put `NA` to estimate parameters otherwise. The lower bound of *a* and *c* parameters are 0.0 and the upper bound are controlled by `bound_a` (default=2.0) and `bound_c` (default=0.25). The lower and upper bound of *b* and *t* parameters are controlled by `bound_b` and `bound_t`, default = 3.5. Both estimators iteratively update the parameters until the maximum iterations (`iter=20` by default) or parameter converges (`conv=0.005` by default). When `debug=TRUE`, return additional data for debugging. The `scale` argument controls on which parameter the scale is set (`theta` vs. `b`), and the `scale_mean` and `scale_sd` specify the mean and standard deviation of the scale (0.0 and 1.0 by default).

In addition, the maximum likelihood estimator has the following arguments: 

* `method`: `jmle` to use joint maximum likelihood estimation and `mmle` to use maximum likelihood estimation
* `mmle_mu`, `mmle_sig`: the mean and standard deviation of the marginal distribution of *t* parameters when `method='mmle'`

The Bayesian estimator has the following arguments:

* `method`: the theta estimation method, `map`(maximum a posteriori) or `eap`(expected a posteriori)
* `t_mu`, `t_sig`: the priors of *t* parameters (normal distribution)
* `a_mu`, `a_sig`: the priors of *a* parameters (log-normal distribution)
* `b_mu`, `b_sig`: the priors of *b* parameters (normal distribution)
* `c_alpha`, `c_beta`: the priors of *c* parameters (beta distribution)
* `reported_sd`: `TRUE` to report the posterior SD of *t* parameters

###### Examples
Example 1: Joint maximum likelihood estimation of all parameters:
```{r}
data <- model_3pl()$gendata(2000, 50)
# joint maximum likelihood estimation
x <- estimate_mle(data$responses, method='jmle')
```

```{r, echo=FALSE}
y <- rbind(melt(data$people), melt(data$items)) %>% 
  rename(params=variable, true=value) %>% 
  mutate(est=c(x$t, x$a, x$b, x$c))
y %>% group_by(params) %>% summarise(n=n(), corr=cor(true, est), rmse=rmse(true, est)) %>% as.data.frame()
y %>% ggplot(aes(x=true, y=est, color=params, alpha=.5)) +
  geom_point() + geom_smooth(method='loess') + 
  facet_wrap(~params, nrow=1, scales='free') + 
  xlab('True Parameters') + ylab('Est. Parameters') +
  theme_bw() + guides(alpha=FALSE)
```

Example 2: Marginal maximum likelihood estimation of all parameters:
```{r}
# marginal maximum likelihood estimation
x <- estimate_mle(data$responses, method='mmle')
```

```{r, echo=FALSE}
y <- rbind(melt(data$people), melt(data$items)) %>% 
  rename(params=variable, true=value) %>% 
  mutate(est=c(x$t, x$a, x$b, x$c))
y %>% group_by(params) %>% summarise(n=n(), corr=cor(true, est), rmse=rmse(true, est)) %>% as.data.frame()
y %>% ggplot(aes(x=true, y=est, color=params, alpha=.5)) +
  geom_point() + geom_smooth(method='loess') + 
  facet_wrap(~params, nrow=1, scales='free') + 
  xlab('True Parameters') + ylab('Est. Parameters') +
  theme_bw() + guides(alpha=FALSE)
```

Example 3: Bayesian estimation of all parameters (EAP for */$theta/* parameters):
```{r}
# bayesian estimation: eap
x <- estimate_mle(data$responses, method='eap')
```

```{r, echo=FALSE}
y <- rbind(melt(data$people), melt(data$items)) %>% 
  rename(params=variable, true=value) %>% 
  mutate(est=c(x$t, x$a, x$b, x$c))
y %>% group_by(params) %>% summarise(n=n(), corr=cor(true, est), rmse=rmse(true, est)) %>% as.data.frame()
y %>% ggplot(aes(x=true, y=est, color=params, alpha=.5)) +
  geom_point() + geom_smooth(method='loess') + 
  facet_wrap(~params, nrow=1, scales='free') + 
  xlab('True Parameters') + ylab('Est. Parameters') +
  theme_bw() + guides(alpha=FALSE)
```

Example 4: Bayesian estimation of all parameters (MAP for */$theta/* parameters):
```{r}
# bayesian estimation: map
x <- estimate_mle(data$responses, method='map')
```

```{r, echo=FALSE}
y <- rbind(melt(data$people), melt(data$items)) %>% 
  rename(params=variable, true=value) %>% 
  mutate(est=c(x$t, x$a, x$b, x$c))
y %>% group_by(params) %>% summarise(n=n(), corr=cor(true, est), rmse=rmse(true, est)) %>% as.data.frame()
y %>% ggplot(aes(x=true, y=est, color=params, alpha=.5)) +
  geom_point() + geom_smooth(method='loess') + 
  facet_wrap(~params, nrow=1, scales='free') + 
  xlab('True Parameters') + ylab('Est. Parameters') +
  theme_bw() + guides(alpha=FALSE)
```

Example 5: Estimator comparison under different sample sizes and test lengths:
```{r, eval=FALSE}
n_samples <- seq(500, 2000, by=500)
n_items <- seq(30, 90, by=30)
params_format <- function(data, x, ns, ni, estimator){
  rbind(data.frame(params='t', true=data$people$theta, est=x$t),
        data.frame(params='a', true=data$items$a, est=x$a),
        data.frame(params='b', true=data$items$b, est=x$b),
        data.frame(params='c', true=data$items$c, est=x$c)) %>%
    mutate(n_sample=ns, n_items=ni, estimator=estimator)
}
results <- NULL
for(ns in n_samples){
  for(ni in n_items){
    cat("data:", ns, "by", ni, "\n")
    data <- model_3pl()$gendata(ns, ni)
    x_jmle <- estimate_mle(data$responses, method='jmle', debug=TRUE)
    x_mmle <- estimate_mle(data$responses, method='mmle', debug=TRUE)
    x_eap <- estimate_bayesian(data$responses, method='eap', debug=TRUE)
    x_map <- estimate_bayesian(data$responses, method='map', debug=TRUE)
    rs <- rbind(params_format(data, x_jmle, ns, ni, 'JMLE'),
          params_format(data, x_mmle, ns, ni, 'MMLE'),
          params_format(data, x_eap, ns, ni, 'EAP'),
          params_format(data, x_map, ns, ni, 'MAP'))
    results <- rbind(results, rs)
  }
}
```

```{r, echo=FALSE}
results %>% group_by(n_sample, n_items, estimator, params) %>% 
  summarise(corr=cor(true, est), rmse=rmse(true, est)) %>%
  ggplot(aes(x=n_sample, y=rmse, color=estimator)) +
  geom_point() + geom_line() + facet_grid(n_items ~ params) + 
  xlab("Sample Sizes") + ylab("Test Length") + theme_bw()
```

Example 6: Fix parameters
```{r}
data <- model_3pl()$gendata(1000, 50)
x <- estimate_mle(data$response, t=data$people$theta)
```

```{r, echo=FALSE}
y <- rbind(data.frame(params='t', true=data$people$theta, est=x$t),
           data.frame(params='a', true=data$items$a, est=x$a),
           data.frame(params='b', true=data$items$b, est=x$b),
           data.frame(params='c', true=data$items$c, est=x$c))
y %>% ggplot(aes(x=true, y=est, color=params, alpha=.5)) +
  geom_point() + geom_smooth(method='loess') + 
  facet_wrap(~params, nrow=1, scales='free') + 
  xlab('True Parameters') + ylab('Est. Parameters') +
  theme_bw() + guides(alpha=FALSE)
```

Example 7: Estimation with missing data
```{r}
data <- model_3pl()$gendata(1000, 50)
na_index <- runif(prod(dim(data$responses))) < .1
data$responses[na_index] <- NA
x <- estimate_mle(data$responses, method='mmle', debug=TRUE, scale="b")
x <- irt_rescale(model_3pl(t=x$t, a=x$a, b=x$b, c=x$c), "theta", 0, 1)
x <- list(t=x$people$theta, a=x$items$a, b=x$items$b, c=x$items$c)
```
```{r, echo=FALSE}
y <- rbind(data.frame(param='t', true=data$people$theta, est=x$t),
           data.frame(param='a', true=data$items$a, est=x$a),
           data.frame(param='b', true=data$items$b, est=x$b),
           data.frame(param='c', true=data$items$c, est=x$c))
ggplot(y, aes(x=true, y=est, color=param)) +
  geom_point(alpha=.5) + facet_wrap(~param, scales="free") +
  xlab("True Params") + ylab("Est. Params") +
  theme_bw()
group_by(y, param) %>% 
  summarise(corr=cor(true, est), rmse=rmse(true, est), mean=mean(est), sd=sd(est)) %>%
  round(., 2)

```


##### Automated Test Assembly
Automated test assembly (ATA) uses advanced optimization algorithms to assemble test forms to satisfy stringent objectives and constraints. Objectives in ATA can be relative (e.g., maximize or minimize difficulty) or absolute (e.g., approach a given test information function). While an ATA problem can be solved by heuristic algorithms [^5][^6], this module implements the mixed integer linear programming (MILP) algorithms [^7]. Compared with heuristic algorithms which are usually fast but cannot guarantee the global optimality, the MILP can arguably solve large and sophisticated problems more efficiently. This module uses the well-known open-source MILP solver:  [lp_solve](http://lpsolve.sourceforge.net/5.5/).

[^5]: Stocking, M. L., & Swanson, L. (1998). Optimal design of item banks for computerized adaptive tests. Applied Psychological Measurement, 22, 271-279.
[^6]: Luecht, R. M. (1998). Computer-assisted test assembly using optimization heuristics. Applied Psychological Measurement, 22, 224-236.
[^7]: van der Linden, W. J., & Reese, L. M. (1998). A model for optimal constrained adaptive testing. Applied Psychological Measurement, 22, 259-270.

Call `ata(pool, nform, len, maxselect, debug)` to construct an *ata* object. Use `ata_obj_relative(ata, coef, mode, negative, flatten, forms, collapse)` and `ata_obj_absolute(ata, coef, target, forms, collapse)` functions to add relative and absolute objective functions to the problem respectively. The relative objective function is to maximize (`mode='max'`) or minimize (`mode='min'`) a given property, whereas the absolute objective functions is to minimize the discrepancy between the objective function and `target`. The `coef` argument can be a pool-size numeric vector, a variable name, or a numeric vector of theta values (when length is not equal to the number of items in the pool). When the optimum is expected to be negative, set `negative=TRUE`, and this is imperative to obtain the correct results. If not `NULL`, the `forms` argument specifies on which forms objectives are set. When `collapse=TRUE`, forms are collapsed into one combined form; otherwise, the same objective is set for each form. 

Use `ata_constraint(ata, coef, min, max, level, forms, collapse)` to add constraints. The `coef` argument can be a variable name, a constant, or a pool-size numeric vector. When `min=NA` or `max=NA`, the lower or the upper bound of the constraint is not set. When `min==max`, the constraint is set to equal to the value. When `coef` is a categorical variable, use `level` to specify which level is constrained. The `forms` and `collapses` work in the same way as in setting objectives.

Use `ata_item_enemy(ata, items)` to add enemy items which should not be selected into the same form. Use `ata_item_fixedvalue(ata, items, min, max, forms, collapse)` to force the selection or not selection of items. Use `ata_item_maxselect(ata, maxselect, items)` to set the maximum number of selection for items.   

Finally, use `ata_solve(ata, as.list, timeout, mip_gap, verbose, ...)` to solve the problem. When `as.list=TRUE`, results are returned in a list, instead of a data frame. The `timeout`, `min_gap`, `verbose` arguments are three important MILP parameters. Additional parameters are taken by `...`. See the documentation of *lpSolveAPI** for more detail. When the problem is successfully solved, the following data are added to the original object:

* `status`: the status of the solution
* `optimum`: the optimal value of the objective function
* `result`: a binary matrix of assembly result
* `items`: a list or data frame of assembled items

Use `plot(ata)` to visualize the TIFs of assembled test forms.


###### Examples
Prep: Generate data
```{r}
n <- 100
items <- model_3pl()$gendata(1, n)$items %>%
  mutate(id=1:n, content=sample(1:3, n, replace=T), time=round(rlnorm(n, 4.1, .2)))
```

Example 1: Assemble 6 parallel forms with 10 items each (use 60% of the pool) to maximize/minimize the *b*-parameters.
```{r}
### maximize difficulty
x <- ata(items, 6, len=10, maxselect=1)
x <- ata_obj_relative(x, "b", "max")
x <- ata_solve(x, as.list=F)
group_by(x$items, form) %>%
  summarise(n=n(), mean=mean(b), sd=sd(b)) %>%
  round(., 2)
### minimize difficulty
x <- ata(items, 6, len=10, maxselect=1)
x <- ata_obj_relative(x, "b", "min", negative=T)
x <- ata_solve(x, as.list=F)
group_by(x$items, form) %>%
  summarise(n=n(), mean=mean(b), sd=sd(b)) %>%
  round(., 2)
```

Example 2: Assemble 4 parallel forms with 10 items each to have the mean and sd of *b* parameters equal to 0 and 1.
```{r}
x <- ata(items, 4, len=10, maxselect=1)
x <- ata_obj_absolute(x, items$b, target=0*10)
x <- ata_obj_absolute(x, items$b^2, target=1*10)
x <- ata_solve(x, as.list=F)
group_by(x$items, form) %>%
  summarise(n=n(), mean=mean(b), sd=sd(b)) %>%
  round(., 2)
```

Example 3: Assemble 2 parallel forms with 10 items each to maximize information over \$theta$=[-1, 1]. Each form has 3 items from content #1, 3 items from content #2, 4 items from content #3, and average response time of 55-65 seconds.
```{r}
x <- ata(items, 2, len=10, maxselect=1) %>%
  ata_obj_relative(c(-1, 0, 1), "max") %>%
  ata_constraint("content", min=3, max=3, level=1) %>%
  ata_constraint("content", min=3, max=3, level=2) %>%
  ata_constraint("content", min=4, max=4, level=3) %>%
  ata_constraint("time", min=55*10, max=65*10) %>%
  ata_solve(as.list=F)
group_by(x$items, form) %>%
  summarise(n=n(), mean_time=mean(time), conten1=sum(content==1), content2=sum(content==2), content3=sum(content==3))
plot(x)
```

Example 4: Assemble 2 parallel forms from an item pool of item sets. Each form should maximize information over \$theta$=[-1, 1], and should have 10 items in 3 content areas as (3, 3, 4). To solve this problem, the item pool should be restructured to collapse items in the set into one entry.
```{r}
# generate item pool
pool <- model_3pl()$gendata(1, 100)$items %>%
  mutate(content=sample(1:3, 100, replace=TRUE), set_id=sample(1:30, 100, replace=T)) %>%
  arrange(set_id)
# collapse item sets: a, b, c parameters are not used, but still required by ATA
info <- irt_stats(model_3pl(theta=c(-1, 0, 1), items=pool), "info") %>% t() %>% as.data.frame()
colnames(info) <- paste("info", 1:3, sep="")
items <- cbind(pool, info) %>% group_by(set_id) %>%
  summarise(n=n(), info1=sum(info1), info2=sum(info2), info3=sum(info3),
            content1=sum(content==1), content2=sum(content==2), content3=sum(content==3),
            a=mean(a), b=mean(b), c=mean(c))
# solve ata problem: don't use the 'len' argument to set length constraints!
x <- ata(items, 2, len=NULL, maxselect=1) %>%
  ata_obj_relative(coef="info1", mode="max") %>%
  ata_obj_relative(coef="info2", mode="max") %>%
  ata_obj_relative(coef="info3", mode="max") %>%
  ata_constraint(coef="n", min=10, max=10) %>%
  ata_constraint(coef="content1", min=3, max=3) %>%
  ata_constraint(coef="content2", min=3, max=3) %>%
  ata_constraint(coef="content3", min=4, max=4) %>%
  ata_solve(as.list=FALSE)
# find orignial items using set_id
x <- select(x$items, form, set_id) %>% merge(x=pool, y=., by="set_id")
arrange(x, form, set_id)
group_by(x, form) %>% summarise(n=n(), content1=sum(content==1), content2=sum(content==2), content3=sum(content==3))
```



##### Computerized Adaptive Testing

Computerized adaptive testing (CAT) takes advantage of the tremendous computing powers of modern computers to customize the test forms to match the test takers' demonstrated abilities during the administration. Studies have shown that CAT could massively improve the testing efficiency and enhance the test security. This module provides a framework for conducting CAT simulation studies with the out-of-box or user-defined selection, estimation, or stopping rules. To change a rule, just pass in the corresponding function in the `cat_sim(true, pool, ...)` function -- e.g., `cat_sim(..., select_rule=new_select_func, estimate_rule=new_estimate_func, stop_rule=new_stop_func)`. When writing a new rule, make sure the function signature is as follows: `function(len, theta, stats, admin, pool, opts)`, where 

* `len` is the current test length
* `theta` is the current $\theta\ estimate
* `stats` is a matrix with 3 columns: `u` for responses, `t` for $\theta\ estimates, and `se` for standard errors
* `admin` is a data frame of administered items
* `pool` is a data frame of the remaining items in the pool
* `opts` is a list of option/control parameters, converted from the `...` argument in the `cat_sim` function.


The following rules are provided as the out-of-box rules:

* `cat_select_default` selects the item with the maximum information or the item set with the maximum averaged information. When working with item sets, group items in the same set with the same identifier and pass the identifier variable name to the `select_id` argument. Use the `randomesque` argument to implement the randomesque item exposure control procedure[^8][^9]. 

* `cat_select_ccat` selects items or item sets to approach the content-balancing targets[^9]. Use `ccat_var` to define the content variable, and `ccat_perc` to define the targets in percentage (decimal numbers). Make sure the elements names of the `ccat_perc` align with the values in `ccat_var`. Use `ccat_init_rand` to add randomness in the selection of the initial content areas. The `select_id` and `randomesque` options are also applicable for this rule.

* `cat_select_shadow` implements the shadow-test CAT item selection algorithm[^10]. Use `shadow_constraints` to define the constraints, which should have four columns: `var` (the constrained variable), `level` (the constrained level in that variable, `NA` for continuous variable), `min` (the lower bound) and `max` (the upper bound). The `select_id` and `randomesque` options are also applicable for this rule.

* `cat_estimate_default` is a maximum likelihood estimator (MLE) of the $\theta\ parameter.

* `cat_estimate_mle_step` is another maximum likelihood estimator of the $\theta\ parameter, but only increment or decrement the $\theta\ by a `mle_step` for all 1s or 0s responses.

* `cat_estimate_eap` is a expected a posteriori (EAP) estimator of the $\theta\ parameter. Use `eap_mean` and `eap_sd` to define the priors.

* `cat_estimate_hybrid` is a hybrid estimator, which uses EAP for all 1s and 0s responses and MLE otherwise. 

* `cat_stop_default` is a trifold stopping rule. It uses the minimum standard error stopping rule when `stop_se` is defined in the options, and the minimum information stopping rule when `stop_mi` is defined in the options, and the 95% confidence interval classification stopping rule when `stop_cut` is defined in the options.

[^8]: Weiss, D. J., & Kingsbury, G. (1984). Application of computerized adaptive testing to educational problems. Journal of Educational Measurement, 21, 361-375.
[^9]: Kingsbury, C. G., & Zara, A. R. (1991). A comparison of procedures for content-sensitive item selection in computerized adaptive tests. Applied Measurement in Education, 4, 241-261.
[^10]: van der Linden, W. J. (2000). Constrained adaptive testing with shadow tests. In Computerized adaptive testing: Theory and practice (pp. 27-52). Springer Netherlands.

The simulation results are wrapped in a *cat* object, which includes `pool` (the remaining pool), `admin` (the administered items), `true` (the true $\theta\) and `theta` (the final $\theta\ estimate)

###### Examples
```{r}
## generate item pool
pool <- model_3pl()$gendata(1, 100)$items
pool$set_id <- sample(1:30, 100, replace=TRUE)
pool$content <- sample(1:3, 100, replace=TRUE)
pool$time <- round(rlnorm(100, mean=4.1, sd=.2))

## use all default rules and options
x <- cat_sim(1.0, pool, min=10, max=20) 
## use randomesque to control exposure in selection
x <- cat_sim(1.0, pool, min=10, max=20, randomesque=5)
## use user-defined identifier to select item sets
x <- cat_sim(1.0, pool, min=10, max=20, selct_id="set")
## use the mle_step estimation rule
x <- cat_sim(1.0, pool, min=10, max=20, estimate_rule=cat_estimate_mle_step, mle_step=.5)
## use the hybrid estimation rule
x <- cat_sim(1.0, pool, min=10, max=20, estimate_rule=cat_estimate_hybrid, eap_mean=0, eap_sd=1)
## use the standard error stopping rule
x <- cat_sim(1.0, pool, min=10, max=20, stop_rule=cat_stop_default, stop_se=.25)
## use the 95% confidence interval classification stopping rule
x <- cat_sim(1.0, pool, min=10, max=20, stop_rule=cat_stop_default, stop_cut=0)
## use the constrained CAT item selection
x <- cat_sim(1.0, pool, min=10, max=20, select_rule=cat_select_ccat, ccat_var='content', ccat_perc=c('1'=.2, '2'=.3, '3'=.5))
## use the constrained CAT item selection with initial randomness
x <- cat_sim(1.0, pool, min=10, max=20, select_rule=cat_select_ccat, ccat_var='content', ccat_perc=c('1'=.2, '2'=.3, '3'=.5), ccat_init_rand=5)
## use the shadow-test CAT
cons <- data.frame(var='content', level=1:3, min=3, max=5)
cons <- rbind(cons, data.frame(var='time', level=NA, min=55*10, max=65*10))
x <- cat_sim(1.0, pool, min=10, max=10, shadow_constraints=cons, select_id="set_id")
## extract CAT history
x$admin
## print and plot results
print(x)
plot(x)
```



##### Multistage Testing

Multistage testing (MST) is an adaptive CBT model that navigates test takers through a set of pre-constructed item sets, spanning over multiple testing stages, in order to create a test form most suited to their abilities. The pre-constructed item sets are called *modules*, the entire collection of modules connected across stages by the routing rules is called a *panel*, and the pathway used to finish the test is called a *route*. A common practice is to have multiple parallel and interchangeable panels in place for administration. One panel will be randomly selected for a test taker to alleviate the item exposure rate. 

With reduced adaptivity, it is difficult for MST to surmount CAT in terms of measurement quality and efficiency. However, because all tests are assembled before administration, the content and psychometric properties of the test can be reviewed before the pulication. This module provides an interface for designing, assembling and simulating a MST.

Call `mst(pool, design, npanel, method, len, maxselect)` to initiate a *mst* object. The design is the structural design of the MST. For instance, `design=c(1, 2, 2)` means a 1-2-2 MST with 3 stages, 5 modules, and 4 routes, and `design=c(1, 2, 3)` means a 1-2-3 MST with 3 stages, 6 modules, and 6 routes. When `method='bottomup'`, the bottom-up design approach is used, meaning objectives  and constraints are imposed on modules. This is a very practical approach and has been commonly used in practice and research. When `method='topdown'`, objectives and constraints are imposed on routes. The top-down approach automatically finds an optimal way to allocate objectives, constraints, and items across stages, but it is a relatively new approach. Internally, the *form* number is the global unique identifier assigned to modules, and the *index* number is the in-panel unique identifier assigned to modules. The former is used for ATA to recognize modules/forms, and the latter is for users to find a module in a given panel. Modules will be indexed sequentially from the first to the last stage. The `module` data frame in a *mst* object shows the mapping between index and stage-module position. The `route` data frame shows all permissible routes. Use `mst_route(mst, route, op)` to add new routes or remove existing routes. In practice, routes with dramatic changes are often prohibited. 

Use `mst_objective(mst, theta, indicies, target, flatten, ...)` to set the TIF objectives. Use the `target` argument to set a target value at given `theta` points. Or, leave it to `NULL` to maximize the information at given `theta` points. Use the `flatten` argument to have a flat TIF. Use `mst_constraint(mst, coef, min, max, level, indicies)` to add constraints. The `min` and `max` arguments are allowed to be `NA`. In the top-down approach, it is likely to have all items allocated to the vary last stage only for optimality. To circumvent this situation, use `mst_stage_length(mst, stages, min, max)` to regulate the test length in earlier stages. Or, use `mst_set_rdp(mst, theta, indices, tol)` and `mst_module_mininfo(mst, theta, mininfo, indices)` to impose the location and minimum information constraints on routing decision points (RDPs), which helps prevent the empty stages/modules. Finally, use `mst_assemble(mst)` to attempt to assemble the MST. If assembled successfully, the *mst* object adds a data frame  of assembled items (called `items`), which adds a few extra columns to indicate the *panel*, *module*, in-panel *index*, and global *form* indices.  Use `mst_get_items(mst, panel, stage, module, route)` to retrieve items from an assembled MST. To visualize the assembly results, call `plot(mst, byroute)`. When `byroute=FALSE`, it draws the TIFs of modules in a panel-by-stage grid. When `byroute=TRUE`, it draws the TIFs of routes in each panel.

Use `mst_sim(mst, true.theta, rdp)` to conduct a simulation on an assembled MST. If `rdp=NULL`, the maximum information routing rule is used. Otherwise, set `rdp` to a list of vectors of RDPs in each stage.  

###### Examples
```{r}
### generate a 300-item pool
pool <- irt_model("3pl")$gendata(1,300)$items
pool$content <- sample(1:3, nrow(pool), replace=TRUE)
pool$time <- round(exp(rnorm(nrow(pool), log(60), .2)))

### ex. 1: 1-2-2 MST, 2 panels, topdown
### 20 items, content = c(10, 5, 5)
### maximize information at -1 and 1 for easy and hard routes
x <- mst(pool, design=c(1, 2, 2), npanel=2, method='topdown', len=20, maxselect=1)
x <- mst_objective(x, theta=-1, indices=1:2)
x <- mst_objective(x, theta= 1, indices=3:4)
x <- mst_constraint(x, coef="content", min=10, max=10, level=1)
x <- mst_constraint(x, coef="content", min=5, max=5, level=2)
x <- mst_constraint(x, coef="content", min=5, max=5, level=3)
x <- mst_stage_length(x, stages=c(1, 2, 3), min=1)
x <- mst_assemble(x, timeout=10)
plot(x)
plot(x, byroute=TRUE)
freq(mst_get_items(x, panel=1, route=1)$content, 1:3)$freq
freq(mst_get_items(x, panel=2, route=4)$content, 1:3)$freq

### ex. 2: 1-2-3 MST, 2 panels, bottomup,
### 10 items in each module, content = c(4, 3, 3)
### maximize information at -1, 0 and 1 for easy, medium, and hard modules
x <- mst(pool, design=c(1, 2, 3), npanel=2, method='bottomup', len=10, maxselect=1)
x <- mst_route(x, c(1, 2, 6), "-")
x <- mst_route(x, c(1, 3, 4), "-")
x <- mst_objective(x, theta= 0, indices=1)
x <- mst_objective(x, theta=-1, indices=c(2,4))
x <- mst_objective(x, theta= 1, indices=c(3,5))
x <- mst_constraint(x, coef="content", min=4, max=4, level=1)
x <- mst_constraint(x, coef="content", min=3, max=3, level=2)
x <- mst_constraint(x, coef="content", min=3, max=3, level=3)
x <- mst_assemble(x, timeout=10)
plot(x)
plot(x, byroute=TRUE)

### ex. 3: 1-2-3 MST, 2 panels, topdown, 30 items,
### 10 items in each content area
### target information at 18 at -1, 0, and 1 for easy, medium and hard routes
x <- mst(pool, design=c(1, 2, 3), npanel=2, method='topdown', len=30, maxselect=1)
x <- mst_route(x, c(1, 2, 6), "-")
x <- mst_route(x, c(1, 3, 4), "-")
x <- mst_objective(x, theta=-1, indices=1, target=16)
x <- mst_objective(x, theta= 0, indices=2:3, target=16)
x <- mst_objective(x, theta= 1, indices=4, target=16)
x <- mst_constraint(x, coef="content", min=10, max=10, level=1)
x <- mst_constraint(x, coef="content", min=10, max=10, level=2)
x <- mst_constraint(x, coef="content", min=10, max=10, level=3)
x <- mst_stage_length(x, stages=c(1, 2, 3), min=3)
x <- mst_assemble(x, timeout=20)
plot(x, byroute=TRUE)

### ex. 4: simulation using the maximum information
y <- mst_sim(x, 0.2)
y$thetas
y$ses
y$route

### ex. 4: simulation using given RPDs
y <- mst_sim(x, -0.2, rdp=list(s1=c(0), s2=c(-.44, .44)))
y$thetas
y$ses
y$route
```


### Graphic User Interfaces

The GUIs built on *shiny* were reomved from this package. I'm trying to put together another standalone packages for GUIs. 


### Ending

Please send your comments, questions, feature request and bug reporting to the author [Xiao Luo](mailto:xluo1986@gmail.com).
